---
title: "VALID-I: Data Quality Reporting Workflow"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{VALID-I: Data Quality Reporting Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r options, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(pointblank)
```

### Introduction to the **Data Quality Reporting** workflow (**VALID-I**)

When trying to assess the state of data quality for tabular data, we want to perform a full accounting of assertions on the data without stopping anywhere in the interrogation of the data. We use an object called an *agent* to collect our validation instructions, perform the interrogation, and then serve as an artifact for reporting or further analysis. The *agent* is created with the `create_agent()` function. We give that agent the name of the target table which, again, can be data frame, tibble (`tbl_df`), or, supported database `tbl` object (`tbl_dbi`).

The agent naturally needs directives on what to do with the table, so, we invoke validation functions. There are lots of them. Some check for the existence or type of column (`col_exists()` or the group of `col_is_*()` functions). Others check each cell in a column for satisfying a specific condition (the `col_vals_*()` functions). We can use as many of these as necessary for satisfactory validation testing of the table in question.

The final function that needs to be called is the `interrogate()` function. You see, the validation functions, when called on an *agent* object don't do anything with the data. They are instructions. With `interrogate()` those instructions turn into actions, with the agent dutifully carrying out the interrogation plan.

For our examples going forward, we'll use the `small_table` dataset. It's included in the **pointblank** package. It isn't very large, which makes it great for simple examples. Here it is in its entirety:

```{r small_table, paged.print=FALSE}
small_table
```

What follows is a very simple validation plan for a very simple table. We will test that:

1. the `date_time` column is indeed a date-time column
2. column `f` only has the values `"low"`, `"mid"`, and `"high"`
3. the values in column `a` are all less than `10`
4. The strings in column `b` fit a particular regex pattern (`"^[0-9]-[a-z]{3}-[0-9]{3}$"`)
5. column `d` has values in the range of `0` to `5000` (this is not entirely true!)

```{r agent_small_table}
agent <- 
  small_table %>%
  create_agent() %>%
  col_is_posix(vars(date_time)) %>%
  col_vals_in_set(vars(f), set = c("low", "mid", "high")) %>%
  col_vals_lt(vars(a), value = 10) %>%
  col_vals_regex(vars(b), regex = "^[0-9]-[a-z]{3}-[0-9]{3}$") %>%
  col_vals_between(vars(d), left = 0, right = 5000) %>%
  interrogate()
```

```
── Interrogation Started - there are 5 steps ──────────────────────────────────
✓ Step 1: OK.
✓ Step 2: OK.
✓ Step 3: OK.
✓ Step 4: OK.
✓ Step 5: OK.

── Interrogation Completed ─────────────────────────────────────────────────
```

The five `OK` messages means that all of the individual validations in each of those five validation steps passed. Printing the `agent` object gives a step-by-step breakdown of the interrogation process.

```{r get_agent_report, eval=FALSE}
agent
```

<img src="images/agent_report.png" width=100%>

Let's take a close look at how to interpret this report. The `STEP` column provides the name of the validation function used as a basis for a validation step. `COLUMNS` shows us the target column for each validation step. The `VALUES` column lists any values required for a validation step. What is `TBL`? That indicates whether the table was mutated just before interrogation in that validation step (via the `preconditions` argument, available in every validation function). The right-facing arrows indicate that the table didn't undergo transformation, and that we are working with the identity table. `EVAL` lets us know whether there would be issues in evaluating the table itself (catching R errors and warnings); the check marks down this column show us that, here, there were no issues.

The total number of test units is provided next in `UNITS`, then the absolute number and fraction of passing test units (`PASS`) and failing test units (`FAIL`). The `W`, `S`, `N` indicators tell us whether we have entered either of the `WARN`, `STOP`, or `NOTIFY` states for each these validation steps. Because we didn't set any threshold levels for these states (that would be done with the `action_levels()` function), they are irrelevant for this report. Finally, the `EXT` column provides an opportunity to download any data extract rows available for failed test units as CSVs. For *step 5*, the `col_vals_between()` validation step, there is a data extract available (with `1` row). We can either download the CSV from the report or examine that extract in **R** with the `get_data_extracts()` function:

```{r get_data_extracts, paged.print=FALSE}
get_data_extracts(agent, i = 5)
```

Recall that validation *step 5* asserted that all values in column `d` should be between `0` and `5000`, however, this extract of `small_table` shows that column `d` has a value of `10000` which lies outside the specified range.

This short demo shows some of the salient features of defining validation steps and interpreting the report. There are many more things you can do. Have a look at the documentation for some of the validation functions for further examples.
