---
title: "Introduction to pointblank"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Intro to pointblank}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r options, message=FALSE, warning=FALSE, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(pointblank)
```

The **pointblank** package is, at its very core, a thing to validate your data. The data specifically needs to be tabular data but could be in the form of **R** data frames and tibbles, or, database tables (`tbl_dbi` objects).

<img src="images/two_different_workflows.png" width=100%>

There are two basic workflows, and they have names to distinguish them: (1) *data quality reporting* and (2) *pipeline-based data validation*. The first aims to make a complete reporting of target table with as many validation step functions as the user wishes to write to get an adequate level of validation coverage for that table. The second workflow is more ideal in a data-transformation pipeline involving tabular data. The principal mode of operation there is to use validation functions to either warn the user of unforeseen data integrity problems or stop the pipeline dead so that dependent, downstream processes (that would use the data to some extent) are never initiated. Both workflows use a common set of validation step functions, 'action levels' (i.e., failure thresholds) can be set in a stepwise manner, and all side effects and reporting behaviors can be defined using **R** functions.

### A Walkthrough of **pointblank** in the Data Quality Reporting Workflow

When trying to assess the state of data quality for any tabular object, we want to perform a full accounting of assertions on the data without stoppage at any point. We use something called an *agent* to collect our validation instructions, perform the interrogation, and then serve as an artifact for reporting. The *agent* is created with the `create_agent()` function. We give that agent the name of the target table which, again, can be data frame, tibble (`tbl_df`), or, any flavor of database `tbl` object (`tbl_dbi`).

The agent naturally needs directives on what to do with the table, so, we invoke validation step functions. There are lots of them. Some check for the existence or type of column (`col_exists()` or the group of `col_is_*()` functions). Others check each cell in a column for satisfying a specific condition (the `col_vals_*()` functions). We can use as many of these as necessary for satisfactory validation testing of the table in question.

The final function that needs to be called is the `interrogate()` function. You see, the validation step functions, when called on an *agent* object don't do anything with the data. They are instructions. With `interrogate()` those instructions turn into actions, with the agent dutifully carrying out the interrogation plan.

For our examples going forward, we'll use the `small_table` dataset. It's included in the **pointblank** package. It isn't very large, which makes it great for simple examples. Here it is in its entirety:

```{r small_table, paged.print=FALSE}
small_table
```

What follows is a very simple validation plan for a very simple table. We will test that:

1. the `date_time` column is indeed a date-time column
2. column `f` only has the values `"low"`, `"mid"`, and `"high"`
3. the values in column `a` are all less than `10`
4. The strings in column `b` fit a particular regex pattern (`"^[0-9]-[a-z]{3}-[0-9]{3}$"`)
5. column `d` has values in the range of `0` to `5000` (this is not entirely true!)

```{r agent_small_table}
agent <- 
  small_table %>%
  create_agent() %>%
  col_is_posix(vars(date_time)) %>%
  col_vals_in_set(vars(f), set = c("low", "mid", "high")) %>%
  col_vals_lt(vars(a), value = 10) %>%
  col_vals_regex(vars(b), regex = "^[0-9]-[a-z]{3}-[0-9]{3}$") %>%
  col_vals_between(vars(d), left = 0, right = 5000) %>%
  interrogate()
```

The five `OK` messages means that all of the individual validations in each of those five validation steps passed. Printing the `agent` object gives a step-by-step breakdown of the interrogation process.

```{r get_agent_report, eval=FALSE}
agent
```

<img src="images/agent_report.png" width=100%>

Let's take a close look at how to interpret this report. The `STEP` column provides the name of the validation step function used as a basis for a validation step. `COLUMNS` shows us the target column for each validation step. The `VALUES` column lists any values required for a validation step. What is `TBL`? That indicates whether the table was mutated just before interrogation in that validation step (via the `preconditions` argument, available in every validation step function). The fancy script 'I' values show us that the table didn't undergo transformation, and that we are working with the identity table. `EVAL` lets us know whether there would be issues in evaluating the table itself (catching R errors and warnings); the check marks down this column show us that, here, there were no issues.

The total number of test units is provided next in `UNITS`, then the number and franction of passing test units (`PASS`), and then the number and fraction of failing test units (`FAIL`). The `W`, `S`, `N` indicators tell us whether we have entered either of the `WARN`, `STOP`, or `NOTIFY` states for these validation steps. Because we didn't set any threshold levels for these states (that would be done with the `action_levels()` function), they are irrelevant for this report. Finally, the `EXTRACT` indicator tells us the number of data extract rows available for failed test units. For *step 5*, the `col_vals_between()` validation step, there is a data extract available (with `1` row). We can examine that extract with the `get_data_extracts()` function:

```{r get_data_extracts, paged.print=FALSE}
get_data_extracts(agent, i = 5)
```

Recall that validation *step 5* asserted that all values in column `d` should be between `0` and `5000`, however, this extract of `small_table` shows that column `d` has a value of `10000` which lies outside the specified range.

This short demo shows some of the salient features of defining validation steps and interpreting the report. There are many more things you can do. Have a look at the documentation for some of the validation step functions for further examples.

### A Walkthrough of **pointblank** in the Pipeline-based Data Validation Workflow

The second workflow, *pipeline-based data validations*, somewhat simplifies the process for checking data directly. There is no *agent* involved here and we instead call validation step functions directly on the data table objects. Because no *agent*, there is no report, and the idea is that the side effects are most important here. We can trigger warnings, raise errors, or write out logs when exceeding specified failure thresholds. The data just passes through the validation functions (some data in, the same data out). Where would we do this? When importing data, for instance, we could pass the incoming data through a few validation step functions, possibly with customized threshold levels set (by default, any test units failing will result in an error). We could also use a set of validation step functions further down the script on transformed data as a QA/QC measure. If bad data quality might be ruinous for a downstream report (especially in an automated context), it's better to stop the process through **pointblank** validation tests and get to the heart of the matter.

Let's adapt the previous example to optimize it to the pipeline-based data validation workflow:

```{r pipeline_small_table, eval=FALSE, paged.print=FALSE}
small_table %>%
  col_is_posix(vars(date_time), actions = al) %>%
  col_vals_in_set(vars(f), set = c("low", "mid", "high"), actions = al) %>%
  col_vals_lt(vars(a), value = 10, actions = al) %>%
  col_vals_regex(vars(b), regex = "^[0-9]-[a-z]{3}-[0-9]{3}$", actions = al) %>%
  col_vals_between(vars(d), left = 0, right = 5000, actions = al)
```

```
Error: Exceedance of failed test units where values in `d` should have been between `0` and `5000`.
The `col_vals_between()` validation failed beyond the absolute threshold level (1).
* failure level (1) >= failure threshold (1) 
```

Great! This stringent threshold setting stopped the evaluation of the pipeline and, in turn, stops the running script if it's deployed and automatically running on the regular. The `action_levels()` function is quite powerful and it allows us to define custom functions to react to entering each of the three states. In this type of workflow we don't need to define those functions, **pointblank** will automatically do the sensible thing and provide a stock `warning()` or `stop()` message.
